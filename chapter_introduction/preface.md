# 前言

就在几年前，不管是大公司还是创业公司，都鲜有工程师和科学家来将深度学习应用到智能产品与服务中。作为深度学习前身的神经网络，才刚刚摆脱被机器学习学术界认为是过时工具的印象。那个时候，即使是机器学习也非新闻头条的常客。它仅仅被看作是一门具有前瞻性，并拥有一系列小范围实际应用的学科。在包含计算机视觉和自然语言处理在内的实际应用通常需要大量的相关领域知识。所以，这些实际应用被视为相互独立的领域，而机器学习只占其中一小部分。

然而仅仅在这几年内，深度学习便令全世界大吃一惊。它极有力地推动了计算机视觉、自然语言处理、自动语音识别、强化学习和统计建模等多个领域的快速发展。随着这些领域的不断进步，我们现在可以制造自动驾驶的汽车，短信、邮件甚至电话的自动回复系统，以及在围棋中击败最优秀人类选手的软件。这些由深度学习带来的新工具也正产生着广泛的影响：它们改变了电影制作和疾病诊断的方式，并在无论是天体物理学还是生物学的各基础科学中扮演越来越重要的角色。

与此同时，深度学习也给它的使用者们带来了独一无二的挑战。任何单一的应用都汇集了各学科的知识。具体来说，应用深度学习需要同时理解

1. 问题的特点和动机；
1. 将上百的多种类型神经网络层通过特定方式组合在一起的模型背后的数学；
1. 在原始数据上拟合深层模型导致的复杂到难以显示表达出来的目标函数的优化算法；
1. 有效训练模型、避免数值计算陷阱以及充分利用硬件性能所需的工程知识；
1. 通过不多的尝试对几十上百个超参数变量选取一组不错数值的经验。

同样，我们作者也面临从未有的挑战：如何在有限的篇幅里糅合深度学习所需要的方方面面知识，从而使得读者能够很快的理解并应用深度学习技术。本书代表了我们一种尝试：我们将教你概念、背景知识和代码；我们将在同一个地方阐述构造问题所需的批判性思维、解决问题所需的数学知识，以及实现解决方案所需的工程知识。

## 含代码、数学、网页、讨论的统一资源

我们在 2017 年 7 月启动了这本书的项目。当时我们需要向用户解释 Apache MXNet 的（在那时的）新接口 Gluon。而我们并没有找到任何一个资源可以同时满足以下几个方面：

1. 包含较新的方法和应用，并不断更新；
1. 广泛覆盖现代深度学习技术并具有一定的技术深度；
1. 既是严谨的教科书，又是包含可运行代码的生动的教程。

那时，我们在博客和 Github 上找到了大量的演示特定深度学习框架（例如用 TensorFlow 进行数值计算）或实现特定模型（例如 AlexNet、ResNet 等）的示例代码。然而，这些示例通常侧重于如何实现给定的方法，却忽略了有关算法设计等方面的探究。虽然在像 Distill 这样的网站或某些博客上出现了一些有关算法设计的讨论，但它们通常仅覆盖深度学习的一小部分，并常常缺少示例代码。另外，我们欣喜地看到了一些有关深度学习的教科书不断问世，其中最著名的要数 Goodfellow、Bengio 和 Courville 的《深度学习》。该书梳理了深度学习背后的众多概念与方法，是一本极为优秀的教材。然而，这类资源并没有将概念描述与实际代码相结合，以致于有时会令读者对如何实现它们感到毫无头绪。最后，商业课程提供者虽然制作了众多的优质资源，但它们的付费门槛依然令不少用户望而生畏。

学习深度学习通常需要参考多方面资料，例如通过教科书或者论文来学习算法，阅读线上文档学习一个深度学习框架如何使用，然后寻找感兴趣算法在这个框架上的实现来摸索如何将它应用到自己的项目中去。将这些不同人撰写的资料整合很不容易。例如如何将公式变量对应到代码变量，区别实现细节的各个变种，以及如何跑起来别人的代码。这样即耗费力气，也需要时间。

有鉴于此，我们正在着手创建一个为实现以下目标的资源：

1. 所有人均可在网上免费获取。
1. 提供足够的技术深度，从而帮助读者实际成为应用深度学习科学家，能够理解背后的数学原理，而不只是照葫芦画瓢。
1. 包含可运行代码，为读者展示如何在实际中解决问题。这样不仅帮助将数学公式对应成实际代码，而且可以通过修改代码观察结果来获取第一手的经验。
1. 允许我们和整个社区不断快速更新内容来紧跟仍在高速发展的深度学习技术。
1. 由包含有关技术细节问答的论坛作为补充，使得大家可以相互答疑并交换经验。

这些目标往往互有冲突：公式、定理和引用最容易通过 LaTeX 进行管理和展示；代码自然应该用简单易懂的 Python 描述；而网页本身应该是一堆 HTML 和配套的 CSS 和 JavaScript。此外，我们希望这个资源可以作为可执行代码、实体书、可下载的 PDF 文档以及网站。然而，目前并没有任何工具可以完美地满足以上需求。因此，我们不得不自己来集成这样的一个工作流。

我们决定在 Github 上分享源代码并允许提交编辑，通过 Jupyter 记事本来整合代码、公式、文本、图片等，使用Sphinx 作为渲染引擎来生成不同输出，以及使用 Discourse 作为论坛。虽然我们的系统尚未完善，但这些选择在互有冲突的目标之间取得了较好的折中。我们相信这可能是使用这种集成工作流发布的第一本书。

## 从在线课程到纸质书

本书的两位中国作者曾每周末在线免费讲授《动手学深度学习》系列课程。课程的讲义自然成为了本书内容的蓝本。这个课程持续了 5 个月，期间近 3 千名同学参与了讨论，贡献了近 5 千多个有价值的讨论。特别是其中几个参加比赛实战的练习很受欢迎。这个课程的受欢迎程度出乎我们的意料。尽管我们将课件和课程视频都公开在了网上，但我们同时觉得出版成纸质书也许能让更多人来知道它，所以我们拜托了人民邮电出版社来负责出版。

从蓝本到成书花费了更多的时间。我们对所有涉及到的技术点补充了背景介绍，使用了更加严谨的写作风格，板式和示意图也修改得更适应纸质书。在对文字的反复校验外，所有的代码执行结果也都是自动生成的。任何改动都会触发运行每一段代码，保证读者在动手实践时能复现结果。

我们的初衷是让更多人更容易地使用深度学习，因此为了让大家能够便利地获取这些资源，我们在网上保留了免费版本，并且通过不收取出版稿费来降低纸质书的价格，使得更多人可以购买。

## 致谢

我们无比感谢本书中英文版稿件的数百名贡献者。他们帮助增添或改进了书中内容并提供了有价值的反馈。特别地，我们要感谢每一位为这本中文版开源书提交内容改动的贡献者们。这些贡献者的Github用户名和姓名（如提供）是：aa12356jm（崔永明）、aaronzs（Aaron Sun）、alues、Andiedie（周长安）、Angzz（李昂）、cgraywang（王晨光）、ChaiBapchya（Chaitanya Prakash Bapat）、daizuozhuo（戴作卓）、danteliujie（刘捷）、daquexian（张建浩）、DarkWings520（梓善）、delphi-tang（唐佐林）、DHRUV536、DL-85（郭晶博）、duanhong169（段弘）、eric-haibin-lin（林海滨）、Evensgn（范舟）、fcbruce（李律）、Feywell（李阳）、fierceX（夏鲁豫）、foreversailor（张鹏）、gcaxuxi（徐曦）、Ghostish（Kangel Zenn）、GYingchao（Richard CUI）、gyp03（郭云鹏）、haojin2（金颢）、hardfish82、hetong007（何通）、hlnull、htoooth、hukun01（Kun Hu）、ibyte2011（刘俊朋）、icemelon9（沈海晨）、inkydragon、Jerryzcn（张钟越）、Jing-Luo（罗晶）、jiqirer（jiqirer）、Jonariguez（贾忠祥）、jwwthu（姜蔚蔚）、kaonashi-tyc（田宇琛）、kevinthesun（王曜）、kli-nlpr（李凯）、lanking520（兰青）、Laurawly（王乐园）、leezu（Leonard Lausen）、leizhag、leocvml（鄭宇翔）、linbojin、lingss0918、LinkHS（杨大卫）、liujia1（刘佳）、loveisp（戴玮）、MachineIntellect（贾老坏）、mingloo、MoodMAX（张亚鹏）、mzchtx、nlpjoe（周俊佐）、noobbull（Liang Jinzheng）、omg2hei、pengyuanzhuo（彭远卓）、PeterHuang2015（黄焖鸡）、piiswrong（解浚源）、Ramlinbird、rebounding（刘铭）、reminisce（吴俊）、rliu054（刘睿）、rongruosong（张绍明）、SnailTyan（刘天池）、starsdeep、sxjscience（施行健）、SyunSiu（孙畔勇）、szha（查晟）、szhengac（郑帅）、Tom-Ren（任杰骥）、wangx404（王鑫）、wangzhe258369、wangzhenhui1992、WenmuZhou（周军）、wlbksy（汪磊）、wudayo、xcnick（徐驰）、XiaGenYuan（夏根源）、xiaotinghe（何孝霆）、XieGuochao（谢国超）、xinetzone（刘新伟）、xmfbit（肖梅峰）、xwind-h（黄晓烽）、yanwenlei（燕文磊）、yidawang（王贻达）、yifeim（马逸飞）、yixuan（邱怡轩）、yongwww（吴勇）、ypwhs（杨培文）、yufengwhy（余峰）、yupbank（Peng Yu）、yuweiw823（王雨薇）、yuxiangw（王宇翔）、yxyphoebe（喻心悦）、yzhao30、yzhliu（刘忆智）、zhanghang1989（张航）、zheng-da（郑达）、zhiics（陈志）、zhouhang95（周航）、zhreshold（张帜）、zijie0（周远）。谢谢你们让这本书变得更好。

此外，我们感谢Amazon Web Services在撰写本书时给予的慷慨支持。如果没有可用的时间、资源以及来自同事的讨论和鼓励，就没有这本书的项目。特别地，经过同事们的校勘，本书的质量得到了极大的提升。在此我们一一列出章节和校勘人，以表示我们由衷的感谢！引言：金颢；预备知识：吴俊；深度学习基础：张航、王晨光、林海滨；深度学习计算：查晟；卷积神经网络：张帜、何通；循环神经网络：查晟；优化算法：郑帅；计算性能：郑达、吴俊；计算机视觉：解浚源、张帜、何通、张航；自然语言处理：王晨光；附录：金颢。我们还要感谢Apache MXNet团队实现了很多本书所需要的特性。

感谢将门创投，特别是王慧和高欣欣为本书的两位中国作者提供在线讲授《动手学深度学习》系列课程的平台。感谢所有参与这一系列课程的数千名同学们。感谢Amazon Web Services中国团队的同事们，特别是费良宏和王晨对作者的支持与鼓励。感谢本书论坛的三位版主（以及论坛ID）：王鑫（yulangwx）、夏鲁豫（fiercex）和杨培文（ypw）。他们牺牲了自己宝贵的休息时间来回复大家的提问。感谢人民邮电出版社的杨海玲老师为我们在本书的出版过程中所提供的各种帮助。

最后，我们要感谢我们的家人。谢谢你们一直陪伴着我们。

诚然，将算法、公式、图片、代码和样例统一进一本适合阅读的书，而且又是一系列有交互式体验的记事本，是对我们极大的挑战。书中难免有很多疏忽的地方，敬请大家原谅，并希望你能通过每一节后面的二维码向我们反映问题。

结尾处，附上陆游的一句诗作为勉励：

> 纸上得来终觉浅，绝知此事要躬行。


阿斯顿·张、李沐、扎卡里 C. 立顿、亚历山大 J. 斯莫拉

2018年12月
